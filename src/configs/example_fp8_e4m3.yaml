# Example FP8 Quantization Config
# This config demonstrates how to run FP8 quantization evaluation on ResNet18

model:
  name: resnet18
  source: torchvision
  weights: IMAGENET1K_V1

adapter:
  type: generic
  quantize_first_layer: false
  quantized_ops: ["Conv2d", "Linear", "BatchNorm2d", "ReLU"]
  input_quantization: false

quantization:
  format: fp8_e4m3
  calib_method: max  # placeholder for future support # TODO: implement 
  bias: 5

dataset:
  name: imagenette
  path: tests/data/imagenette2-320/val
  batch_size: 32
  num_workers: 8

# Evaluation settings
evaluation:
  # Mode: "eval_only" (run quant model alone), "compare_only" (comparison only), "both"
  mode: compare
  
  # Number of batches for comparison (-1 for all batches)
  compare_batches: -1
